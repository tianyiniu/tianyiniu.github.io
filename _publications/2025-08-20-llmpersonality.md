---
title: "Chameleon LMMs: User Personas Influence Chatbot Personality Shifts"
collection: publications
category: manuscripts
permalink: /publication/2025-08-20-llmpersonality
excerpt: ''
date: 2025-08-20
venue: 'The 2025 Conference on Empirical Methods in Natural Language Processing'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
# paperurl: 'http://academicpages.github.io/files/paper1.pdf'
# bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

**Authors**

Jane Xing, <u>Tianyi Niu</u>, Shashank Srivastava

**Abstract**

As large language models (LLMs) integrate into society, their ability to adapt to users is as critical as their accuracy. While prior work has used personality tests to examine the perceived personalities of LLMs, little research has explored whether LLMs adapt their perceived personalities in response to user interactions. We investigate whether and how LLMs exhibit conversational adaptations over prolonged interactions. Using a controlled simulations where a user and chatbot engage in dialogue, we measure the chatbotâ€™s personality shift before and after the conversation. Across multiple models, we find that traits such as Agreeableness, Extraversion, and Conscientiousness are highly susceptible to user influence, whereas Emotional Stability and Intellect remain relatively more stable. Our results suggest that LLMs dynamically adjust their conversational style in response to user personas, raising important implications for AI alignment, trust, and safety.

**Paper**: Coming soon...

**Code**: Coming soon...